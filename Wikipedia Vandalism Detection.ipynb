{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting data for 24 articles...\n",
      "Getting revision data for 'Donald Trump'...\n",
      "Getting revision data for 'Joe Biden'...\n",
      "Getting revision data for 'Hillary Clinton'...\n",
      "Getting revision data for 'Barack Obama'...\n",
      "Getting revision data for 'Vladimir Putin'...\n",
      "Getting revision data for 'Climate change'...\n",
      "Getting revision data for 'COVID-19'...\n",
      "Getting revision data for 'Abortion'...\n",
      "Getting revision data for 'Gun control'...\n",
      "Getting revision data for 'Israel-Palestine conflict'...\n",
      "Getting revision data for 'Taylor Swift'...\n",
      "Getting revision data for 'BTS (band)'...\n",
      "Getting revision data for 'Game of Thrones'...\n",
      "Getting revision data for 'Star Wars'...\n",
      "Getting revision data for 'Manchester United F.C.'...\n",
      "Getting revision data for 'Real Madrid CF'...\n",
      "Getting revision data for 'Bitcoin'...\n",
      "Getting revision data for 'Elon Musk'...\n",
      "Getting revision data for 'Facebook'...\n",
      "Getting revision data for 'Apple Inc.'...\n",
      "Getting revision data for 'September 11 attacks'...\n",
      "Getting revision data for 'Holocaust'...\n",
      "Getting revision data for 'Evolution'...\n",
      "Getting revision data for 'Vaccination'...\n",
      "\n",
      "Dataset statistics:\n",
      "Total revisions collected: 1067\n",
      "Potential vandalism cases: 104\n",
      "Overall vandalism percentage: 9.75%\n",
      "\n",
      "Vandalism rates by article:\n",
      "                           count  sum  mean  percentage\n",
      "article                                                \n",
      "Vaccination                   50   15  0.30       30.00\n",
      "Barack Obama                  50   12  0.24       24.00\n",
      "Evolution                     50   10  0.20       20.00\n",
      "Joe Biden                     50    8  0.16       16.00\n",
      "COVID-19                      50    7  0.14       14.00\n",
      "Abortion                      50    5  0.10       10.00\n",
      "Bitcoin                       50    5  0.10       10.00\n",
      "Climate change                50    5  0.10       10.00\n",
      "Donald Trump                  50    5  0.10       10.00\n",
      "Taylor Swift                  50    5  0.10       10.00\n",
      "September 11 attacks          50    5  0.10       10.00\n",
      "Star Wars                     50    3  0.06        6.00\n",
      "Real Madrid CF                50    3  0.06        6.00\n",
      "Gun control                   50    3  0.06        6.00\n",
      "Apple Inc.                    50    3  0.06        6.00\n",
      "Elon Musk                     50    3  0.06        6.00\n",
      "Hillary Clinton               50    2  0.04        4.00\n",
      "Game of Thrones               50    2  0.04        4.00\n",
      "Facebook                      50    2  0.04        4.00\n",
      "Vladimir Putin                50    1  0.02        2.00\n",
      "Holocaust                      9    0  0.00        0.00\n",
      "Israel-Palestine conflict      5    0  0.00        0.00\n",
      "Manchester United F.C.        50    0  0.00        0.00\n",
      "BTS (band)                     3    0  0.00        0.00\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def get_simple_revision_data(article_title, max_revs=100):\n",
    "    \"\"\"\n",
    "    Simple function to get Wikipedia revision history for an article.\n",
    "    \"\"\"\n",
    "    # Format article title for API\n",
    "    title = article_title.replace(' ', '_')\n",
    "    \n",
    "    # API endpoint\n",
    "    api_url = \"https://en.wikipedia.org/w/api.php\"\n",
    "    \n",
    "    # Basic parameters\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"format\": \"json\",\n",
    "        \"prop\": \"revisions\",\n",
    "        \"titles\": title,\n",
    "        \"rvprop\": \"ids|timestamp|user|comment|size\",\n",
    "        \"rvlimit\": max_revs\n",
    "    }\n",
    "    \n",
    "    # Make request\n",
    "    response = requests.get(api_url, params=params)\n",
    "    data = response.json()\n",
    "    \n",
    "    # Extract page ID\n",
    "    page_id = list(data['query']['pages'].keys())[0]\n",
    "    \n",
    "    # Get revisions\n",
    "    revisions = []\n",
    "    if 'revisions' in data['query']['pages'][page_id]:\n",
    "        revisions = data['query']['pages'][page_id]['revisions']\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    rev_data = []\n",
    "    for i, rev in enumerate(revisions):\n",
    "        # Calculate size difference if possible\n",
    "        diff_size = None\n",
    "        if i < len(revisions) - 1:\n",
    "            diff_size = rev.get('size', 0) - revisions[i+1].get('size', 0)\n",
    "        \n",
    "        rev_data.append({\n",
    "            'revid': rev['revid'],\n",
    "            'user': rev.get('user', 'Anonymous'),\n",
    "            'timestamp': rev.get('timestamp'),\n",
    "            'comment': rev.get('comment', ''),\n",
    "            'size': rev.get('size', 0),\n",
    "            'diff_size': diff_size,\n",
    "            'article': article_title,\n",
    "            # Simple vandalism heuristic\n",
    "            'possible_vandalism': 'revert' in rev.get('comment', '').lower() or \n",
    "                                  'vandal' in rev.get('comment', '').lower() or\n",
    "                                  abs(diff_size if diff_size else 0) > 1000\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(rev_data)\n",
    "\n",
    "def get_all_articles_data(articles_list, revs_per_article=100):\n",
    "    \"\"\"\n",
    "    Get revision data for multiple articles and combine them.\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    \n",
    "    for article in articles_list:\n",
    "        print(f\"Getting revision data for '{article}'...\")\n",
    "        try:\n",
    "            article_df = get_simple_revision_data(article, max_revs=revs_per_article)\n",
    "            all_data.append(article_df)\n",
    "            # Be nice to Wikipedia's servers\n",
    "            time.sleep(1)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing '{article}': {str(e)}\")\n",
    "    \n",
    "    # Combine all data\n",
    "    if all_data:\n",
    "        combined_df = pd.concat(all_data, ignore_index=True)\n",
    "        return combined_df\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # List of articles known for vandalism issues\n",
    "    vandalism_prone_articles = [\n",
    "        # Controversial political figures\n",
    "        \"Donald Trump\",\n",
    "        \"Joe Biden\",\n",
    "        \"Hillary Clinton\",\n",
    "        \"Barack Obama\",\n",
    "        \"Vladimir Putin\",\n",
    "        \n",
    "        # Controversial topics\n",
    "        \"Climate change\",\n",
    "        \"COVID-19\",\n",
    "        \"Abortion\",\n",
    "        \"Gun control\",\n",
    "        \"Israel-Palestine conflict\",\n",
    "        \n",
    "        # Popular culture\n",
    "        \"Taylor Swift\",\n",
    "        \"BTS (band)\",\n",
    "        \"Game of Thrones\",\n",
    "        \"Star Wars\",\n",
    "        \n",
    "        # Sports teams with rivalries\n",
    "        \"Manchester United F.C.\",\n",
    "        \"Real Madrid CF\",\n",
    "        \n",
    "        # Technology/finance\n",
    "        \"Bitcoin\",\n",
    "        \"Elon Musk\",\n",
    "        \"Facebook\",\n",
    "        \"Apple Inc.\",\n",
    "        \n",
    "        # Historical events\n",
    "        \"September 11 attacks\",\n",
    "        \"Holocaust\",\n",
    "        \n",
    "        # Scientific topics\n",
    "        \"Evolution\",\n",
    "        \"Vaccination\"\n",
    "    ]\n",
    "    \n",
    "    # Get a smaller subset if you want faster results\n",
    "    # articles_to_process = vandalism_prone_articles[:5]  # Uncomment to use just 5 articles\n",
    "    articles_to_process = vandalism_prone_articles\n",
    "    \n",
    "    # Get the data\n",
    "    print(f\"Collecting data for {len(articles_to_process)} articles...\")\n",
    "    combined_df = get_all_articles_data(articles_to_process, revs_per_article=50)\n",
    "    \n",
    "    # Save to CSV\n",
    "    combined_df.to_csv('wikipedia_vandalism_dataset.csv', index=False)\n",
    "    \n",
    "    # Show basic stats\n",
    "    print(\"\\nDataset statistics:\")\n",
    "    print(f\"Total revisions collected: {len(combined_df)}\")\n",
    "    print(f\"Potential vandalism cases: {combined_df['possible_vandalism'].sum()}\")\n",
    "    print(f\"Overall vandalism percentage: {combined_df['possible_vandalism'].mean() * 100:.2f}%\")\n",
    "    \n",
    "    # Show per-article statistics\n",
    "    print(\"\\nVandalism rates by article:\")\n",
    "    article_stats = combined_df.groupby('article')['possible_vandalism'].agg(['count', 'sum', 'mean'])\n",
    "    article_stats = article_stats.sort_values('mean', ascending=False)\n",
    "    article_stats['percentage'] = article_stats['mean'] * 100\n",
    "    print(article_stats.to_string(float_format=\"{:.2f}\".format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1067 entries, 0 to 1066\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   revid               1067 non-null   int64  \n",
      " 1   user                1067 non-null   object \n",
      " 2   timestamp           1067 non-null   object \n",
      " 3   comment             921 non-null    object \n",
      " 4   size                1067 non-null   int64  \n",
      " 5   diff_size           1043 non-null   float64\n",
      " 6   article             1067 non-null   object \n",
      " 7   possible_vandalism  1067 non-null   bool   \n",
      "dtypes: bool(1), float64(1), int64(2), object(4)\n",
      "memory usage: 59.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"wikipedia_vandalism_dataset.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
